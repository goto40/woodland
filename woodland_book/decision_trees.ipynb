{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    " * pruning: helps agains overfitting\n",
    " * decision trees within an ensemble $\\rightarrow$ stability\n",
    " * balance data sets $\\rightarrow$ else you get biased trees\n",
    "\n",
    "## Initial example (from the scikit-learn website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz, pydotplus\n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=iris.feature_names,  \n",
    "                      class_names=iris.target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(pydot_graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree\n",
    "\n",
    "def get_code(tree, feature_names):\n",
    "    left      = tree.tree_.children_left\n",
    "    right     = tree.tree_.children_right\n",
    "    threshold = tree.tree_.threshold\n",
    "    features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "    value = tree.tree_.value\n",
    "\n",
    "    def recurse(left, right, threshold, features, node, indent=0):\n",
    "        if (threshold[node] != -2):\n",
    "            print(\" \"*indent + \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\")\n",
    "            if left[node] != -1:\n",
    "                recurse (left, right, threshold, features,left[node], indent+2)\n",
    "            print(\" \"*indent + \"} else {\")\n",
    "            if right[node] != -1:\n",
    "                recurse (left, right, threshold, features,right[node], indent+2)\n",
    "            print(\" \"*indent + \"}\")\n",
    "        else:\n",
    "            print(\" \"*(indent) + \"return \" + str(value[node]))\n",
    "\n",
    "    recurse(left, right, threshold, features, 0)\n",
    "\n",
    "get_code(clf,iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example problems\n",
    "\n",
    "Define some problem sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "\n",
    "def make_dataframe(**kwargs):\n",
    "    from pandas import DataFrame\n",
    "    return DataFrame(kwargs)\n",
    "\n",
    "def my_plot_2D_data(D,T=None):\n",
    "    if T is None:\n",
    "        dataframe=D\n",
    "    else:\n",
    "        dataframe = make_dataframe( x=D[:,0], y=D[:,1], target=T )\n",
    "    for target, data in dataframe.groupby(\"target\"):\n",
    "        plot(data.x, data.y, 'o', label=f\"target={target}\")\n",
    "        \n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "\n",
    "def my_make_blobs(n=2,a=3, xscale=1, yscale=1, xshift=0,nb_classes=2,n_samples=100):\n",
    "    centers = [[0,0],[a,a],[a*2,0],[a,-a],\n",
    "               [a,2*a]]\n",
    "    D,T = make_blobs(\n",
    "        n_samples=n_samples,\n",
    "        centers=centers[0:n],\n",
    "        cluster_std=1,\n",
    "        n_features=2, \n",
    "        random_state=0\n",
    "    )\n",
    "    T = T%nb_classes\n",
    "    return make_dataframe( x=D[:,0]*xscale+xshift, y=D[:,1]*yscale, target=T )\n",
    "\n",
    "def my_circles():\n",
    "    D,T = make_circles(\n",
    "        n_samples=50,\n",
    "        shuffle=True,\n",
    "        noise=0.1,\n",
    "        random_state=0, \n",
    "        factor=0.5\n",
    "    )\n",
    "    D2,T2 = make_circles(\n",
    "        n_samples=100,\n",
    "        shuffle=True,\n",
    "        noise=0.05,\n",
    "        random_state=0, \n",
    "        factor=0.5\n",
    "    )\n",
    "    D = concatenate((D,4*D2[T2==1,:]), axis=0)\n",
    "    T = concatenate((T,T2[T2==1]), axis=0)\n",
    "    return make_dataframe( x=D[:,0], y=D[:,1], target=T )\n",
    "\n",
    "def my_make_moons():\n",
    "    D,T = make_moons(\n",
    "        n_samples=300, \n",
    "        shuffle=True,\n",
    "        noise=0.2, \n",
    "        random_state=0\n",
    "    )\n",
    "    T = T%2\n",
    "    return make_dataframe( x=D[:,0], y=D[:,1], target=T )\n",
    "\n",
    "def make_challenge(level):\n",
    "    if level==0: return my_make_blobs(2)\n",
    "    elif level==1: return my_make_blobs(3)\n",
    "    elif level==2: return my_make_blobs(4)\n",
    "    elif level==3: return my_circles()\n",
    "    elif level==4: return my_make_moons()\n",
    "    raise Exception(f\"unknown level f{level}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[15,3])\n",
    "N=5\n",
    "idx=0\n",
    "for n in range(N):\n",
    "    idx += 1\n",
    "    subplot(1,N,idx)\n",
    "    dataframe = make_challenge(n)\n",
    "    x = dataframe[[\"x\"]].values.flatten()\n",
    "    y = dataframe[[\"y\"]].values.flatten()\n",
    "    label = dataframe[[\"target\"]].values.flatten()*2-1\n",
    "    plot( x[label==+1], y[label==+1], 'go' )\n",
    "    plot( x[label==-1], y[label==-1], 'ro' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and display classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "def train_and_show(model, dataframe):\n",
    "    x = dataframe[[\"x\"]].values.flatten()\n",
    "    y = dataframe[[\"y\"]].values.flatten()\n",
    "    label = dataframe[[\"target\"]].values.flatten()*2-1\n",
    "\n",
    "    X_train = dataframe[[\"x\",\"y\"]].values\n",
    "    y_train = dataframe[[\"target\"]].values*2-1\n",
    "    y_train = y_train.reshape(( len(y_train), ))\n",
    "    model = model.fit(X_train, y_train)    \n",
    "    \n",
    "    N=100\n",
    "    X,Y = meshgrid( linspace(min(x),max(x),N), linspace(min(y),max(y),N) )\n",
    "    D = stack((X.flatten(), Y.flatten())).transpose()\n",
    "    T = model.predict(D)\n",
    "    #print(T.shape)\n",
    "\n",
    "    T=T.flatten().reshape(X.shape)\n",
    "    contourf(X,Y,sign(T),colors=['#FFAAAA','#AAFFAA'], extend=True)\n",
    "\n",
    "    plot( x[label==+1], y[label==+1], 'go' )\n",
    "    plot( x[label==-1], y[label==-1], 'ro' )\n",
    "    \n",
    "    \n",
    "model = tree.DecisionTreeClassifier()\n",
    "train_and_show(model, my_make_blobs(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example classification (simple decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[15,5])\n",
    "N=5\n",
    "idx=0\n",
    "for n in range(N):\n",
    "    idx += 1\n",
    "    subplot(1,N,idx)\n",
    "    model = tree.DecisionTreeClassifier(random_state=0)\n",
    "    train_and_show(model, make_challenge(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "N=5\n",
    "idx=0\n",
    "params=[1,10,100,300]\n",
    "M=len(params)\n",
    "\n",
    "figure(figsize=[15,5*M])\n",
    "for m in range(M):   \n",
    "    for n in range(N):\n",
    "        if n==1:\n",
    "            ylabel(f\"num estims.={params[m]}\")\n",
    "        idx += 1\n",
    "        subplot(M,N,idx)\n",
    "        model = RandomForestClassifier(random_state=0, n_estimators=params[m])\n",
    "        train_and_show(model, make_challenge(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "N=5\n",
    "idx=0\n",
    "params=[0, 0.05, 0.1, 0.2]\n",
    "M=len(params)\n",
    "\n",
    "figure(figsize=[15,5*M])\n",
    "for m in range(M):   \n",
    "    for n in range(N):\n",
    "        if n==1:\n",
    "            ylabel(f\"ccp_alpha={params[m]}\")\n",
    "        idx += 1\n",
    "        subplot(M,N,idx)\n",
    "        model = RandomForestClassifier(random_state=0, n_estimators=100, ccp_alpha=params[m])\n",
    "        train_and_show(model, make_challenge(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
